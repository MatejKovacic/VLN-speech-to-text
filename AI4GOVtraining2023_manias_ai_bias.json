{
  "AI4GOVtraining2023_manias_ai_bias": {
    "001_AI_and_bias_bias_in_algorithms_bias_in_data_": [
      "Georgios Manias",
      "Tania",
      "AI4Gov Project",
      "First Exam",
      "Presenation",
      "Biosemantic Integration",
      "Economy",
      "Transformation",
      "Real-life Governance",
      "Models of Transformation",
      "Improve",
      "Confront"
    ],
    "002_Outline": [
      "Artificial Intelligence",
      "Modern Societies",
      "Eric",
      "Models AI",
      "Bias AI",
      "Real Scenarios",
      "Financial Uses",
      "Data Bias",
      "Google",
      "IBM",
      "Anticipate Bias AI",
      "Collaboration",
      "AI4Gov-project",
      "Secure AI"
    ],
    "003_AI_IN_MODERN_SOCIETIES": [
      "AI",
      "create",
      "accountability",
      "project",
      "autonomous",
      "vehicles",
      "system",
      "daily",
      "life",
      "sectors"
    ],
    "004_Datamakes_the_world_go_around_": [
      "AI",
      "World",
      "Advance",
      "Capabilities",
      "Models",
      "Analysis",
      "Human",
      "Limitations",
      "ArtificialIntelligence",
      "Performance",
      "Efficiency",
      "Time",
      "Better",
      "Faster",
      "Exceed",
      "HumanLimitations",
      "Vehicle",
      "Capability"
    ],
    "005_THREATS_OF_AI": [
      "AI",
      "Models",
      "Lives",
      "Societies",
      "Autonomous",
      "Vehicles",
      "Governance",
      "Health",
      "Challenges",
      "Ethics",
      "Regulations",
      "World",
      "Europe",
      "GPD"
    ],
    "006_WHAT_IS_AI_BIAS_": [
      "AI",
      "Bias",
      "Artificial Intelligence Development",
      "Decisions",
      "Models",
      "Human-made",
      "Real-world",
      "Impact",
      "Policies",
      "Explanations",
      "Consequences"
    ],
    "007_EXAMPLES_OF_AI_BIAS_IN_REAL_WORLD": [
      "ArtificialModels",
      "Implementation",
      "RealWorld",
      "Examples",
      "Algorithms",
      "Amazon",
      "Google",
      "HumanData",
      "MachineLearning",
      "Bias"
    ],
    "008_WHAT_ARE_THE_TYPES_OF_BIAS_IN_AI_": [
      "data",
      "algorithms",
      "create",
      "specific",
      "used",
      "institute",
      "States",
      "procedures",
      "human",
      "systematic",
      "information",
      "results",
      "people",
      "programs",
      "house",
      "AI"
    ],
    "009_IMPACT_OF_BIAS_IN_TECH_LANDSCAPE": [
      "Artificial_creation",
      "Cybernetic_controllers",
      "United_States",
      "Technology",
      "Trust",
      "Security",
      "Safety",
      "Impact",
      "Society",
      "Characterization",
      "Result",
      "Percentage",
      "Public_sector",
      "Common",
      "Environment"
    ],
    "010_COMMON_FORMS_OF_BIAS_IN_AI": [
      "AI",
      "Auto-completion",
      "Algorithm",
      "Bias",
      "Data",
      "Model",
      "Decision",
      "Choice",
      "Performance",
      "Greece",
      "Election",
      "Accuracy",
      "Family",
      "Explanation",
      "Context",
      "Requirement",
      "Interest",
      "Development",
      "Iteration"
    ],
    "011_WIDELY_USED_TOOLS_TO_MITIGATE_BIAS_IN_AI": [
      "Model",
      "participate",
      "entire operation",
      "work",
      "shape",
      "Google",
      "IBM",
      "What-If-Tool",
      "AI-Fairness-360",
      "better",
      "artificial",
      "fairness",
      "human",
      "systemic",
      "Facebook AI",
      "specific techniques",
      "PwC",
      "platform",
      "different",
      "data-driven",
      "various examinations"
    ],
    "012_HOW_TO_BETTER_TACKLE_BIAS_IN_AI_": [
      "artificial intelligence",
      "system",
      "people",
      "model",
      "data",
      "algorithms",
      "bias",
      "analysis",
      "collaboration",
      "humanity",
      "research",
      "state",
      "function",
      "BIAS",
      "tools",
      "examination",
      "methods"
    ],
    "013_HOW_AI4GOV_MITIGATES_BIAS_": [
      "AI4Go",
      "Improve Results",
      "Ambiguity",
      "Project",
      "Collaboration",
      "Culture",
      "Expertise",
      "Assessments",
      "GDPR",
      "EEAK",
      "Policies",
      "Models",
      "Tools",
      "Economic Approach",
      "Education",
      "Objectives",
      "Trust",
      "Easy Identification",
      "Markets"
    ],
    "014_HOW_AI4GOV_CREATES_RESPONSIBLE_AND_TRUSTWORTHY_AI_": [
      "AI",
      "Application",
      "Governance",
      "Ethics",
      "AI Applications",
      "Dialogue Systems",
      "Techniques AI",
      "Citizens",
      "Education",
      "Program",
      "Politics",
      "Inform",
      "Threats",
      "Use"
    ],
    "015_If_not_now_then_when_": [
      "Artificial Intelligence",
      "Bias",
      "Control",
      "AI Bias",
      "System",
      "European Union",
      "KD4D",
      "ITHACA",
      "Collaboration",
      "Better AI",
      "Work",
      "Effort",
      "Better Models",
      "Synergy"
    ]
  }
}
